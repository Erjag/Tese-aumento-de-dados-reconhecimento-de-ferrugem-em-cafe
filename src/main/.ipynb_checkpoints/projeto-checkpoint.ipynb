{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import os\n","import sys\n","current_path = os.path.abspath('.')\n","root_path = os.path.dirname(os.path.dirname(current_path))\n","sys.path.append(root_path)\n","sys.path.append(os.path.abspath(\"../util\"))\n","import random\n","import time\n","import datetime\n","import copy\n","import itertools\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from torch import nn, optim\n","from torchvision import transforms, models, datasets\n","from torch.autograd import Variable\n","from torchvision import utils\n","from sklearn import metrics\n","from sklearn.model_selection import KFold\n","import splitfolders\n","import gc \n","from NNs import initialize_model, train_model\n","from relatorios import plot_confusion_matrix, plot_loss_accuracy, generate_classification_report \n","from Augmentation_funcs import  ConditionalAugmentation\n","#from AdjustColorSpace import *\n","import splitfolders\n","import gc\n","import torch\n","import math\n","import cv2\n","#from openslide import OpenSlideError\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","MAGNIFICATION_SCALE = {\n","    \"20.0\": 1.0,\n","    \"10.0\": 2.0,\n","    \"5.0\": 4.0,\n","    \"2.5\": 8.0,\n","    \"1.25\": 16.0,\n","    \"0.625\": 32.0,\n","    \"0.3125\": 64.0,\n","    \"0.15625\": 128.0,\n","    \"0.078125\": 256.0\n","}\n","def get_scale_by_magnification(magnification):\n","    return MAGNIFICATION_SCALE[str(magnification)]\n","# retirar depois\n","def adjust_color_space(image):\n","        # Converter a imagem PIL para um array NumPy (RGB)\n","    image_np = np.array(image)\n","    # Converter a imagem para o espaço de cores LAB\n","    lab_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)\n","    # Separar os canais L, A, B\n","    l_channel, a_channel, b_channel = cv2.split(lab_image)\n","    # Ajustar os canais\n","     #Aumentar o contraste do canal de luminosidade\n","    l_channel = cv2.equalizeHist(l_channel)\n","    # Ajuste opcional: aumentar ou diminuir o contraste de cor nos canais A e B\n","    a_channel = cv2.add(a_channel, 10)  # Pequeno aumento na tonalidade verde-vermelha\n","    b_channel = cv2.add(b_channel, 10)  # Pequeno aumento na tonalidade azul-amarela\n","    # Reunir os canais ajustados\n","    adjusted_lab_image = cv2.merge((l_channel, a_channel, b_channel))\n","    # Converter de volta para o espaço de cores RGB\n","    adjusted_image = cv2.cvtColor(adjusted_lab_image, cv2.COLOR_LAB2RGB)\n","    #Converter de volta para PIL antes de retornar\n","    return Image.fromarray(adjusted_image)\n","    #print('aumentou o dado')\n","\n","dataset_dir = \"../../datasets\"\n","model_dir = \"../../models\"\n","color_model = \"LAB\"\n","magnification = 0.625\n","scale = get_scale_by_magnification(magnification)\n","tile_size = 20\n","tile_size_original = int(scale * tile_size)\n","patch_size = (tile_size_original, tile_size_original)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# print('\\nDevice: {0}'.format(device))\n","# print(torch.cuda.get_device_name(0))\n","# !nvidia-smi\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.benchmark = True\n","torch.backends.cudnn.deterministic = True\n","# Define o caminho base do diretório de imagens divididas \n","base_dir = r'C:\\Users\\Augusto\\Documents\\tese\\files\\imagens\\Photos'\n","for model in ['resnet', 'alexnet']:#, 'vgg', 'squeezenet', 'densenet', 'inception']:\n","    \n","    basic_parameters = {\n","    #'num_classes' : 2,\n","    #'class_names': ['healthy', 'unhealthy'],\n","    'num_classes' : 6,\n","    'class_names': ['healthy','red_spider_mite', 'rust_level_1','rust_level_2','rust_level_3','rust_level_4'],\n","    'batch_size' : 32,\n","    'lr' : 0.001, # Taxa de aprendizado\n","    'mm' : 0.9, # Mommentum\n","    'epochs' : 10,\n","    'model_name' : model, # Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n","    'criterion' : nn.CrossEntropyLoss(), # Função de perda\n","    'data_augmentation' :['0','1','2','3','4','5'] #['0','1','2','3'] # 0 - None, 1 - none + aug-basic, 2 - none + aug-avanced, 3 -aug-basic, 4 - aug-avanced, 5 - aug-basic + aug-avanced\n","    }\n","    model_ft, input_size = initialize_model(basic_parameters.get('model_name'), basic_parameters.get('num_classes'))\n","        # Definir as transformações básicas\n","    basic_augmentation = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.RandomResizedCrop(input_size),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Translação\n","        transforms.RandomRotation(30)\n","    ])\n","    advanced_augmentation = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.Lambda(adjust_color_space),  # Ajuste de cor\n","        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))  # Desfoque\n","    ])  \n","    for type_aug in basic_parameters.get('data_augmentation'):\n","        # Obtenção do parâmetro isAugment a partir de basic_parameters\n","        # Configuração do pipeline de transformações com base em isAugment\n","        if type_aug == '0':\n","            # Sem aumento de dados\n","            data_transforms = {\n","                'train': transforms.Compose([\n","                    transforms.Resize(input_size),\n","                    transforms.CenterCrop(input_size),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","                ]),\n","                'val': transforms.Compose([\n","                    transforms.Resize(input_size),\n","                    transforms.CenterCrop(input_size),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","                ]),\n","            }\n","        else:\n","            # Aumento de dados com ou sem ConditionalAugmentation, dependendo de isAugment\n","            if type_aug == '1':\n","                train_transforms = transforms.Compose([\n","                    transforms.Resize(input_size),\n","                    transforms.CenterCrop(input_size),\n","                    ConditionalAugmentation(basic_augmentation, probability=0.5),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","                ])\n","            elif type_aug == '2':\n","                train_transforms = transforms.Compose([\n","                    transforms.Resize(input_size),\n","                    transforms.CenterCrop(input_size),\n","                    ConditionalAugmentation(advanced_augmentation, probability=0.5),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","                ])\n","            elif type_aug == '3':\n","                train_transforms = transforms.Compose([\n","                    basic_augmentation,\n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","                ])\n","            elif type_aug == '4':\n","                train_transforms = transforms.Compose([\n","                    basic_augmentation,\n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","                ])\n","            elif type_aug == '5':\n","                # Exemplo: Adicionando GaussianBlur\n","                train_transforms = transforms.Compose([\n","                    basic_augmentation,\n","                    advanced_augmentation,\n","                   \n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","                ])\n","            data_transforms = {\n","                'train': train_transforms,\n","                'val': transforms.Compose([\n","                    transforms.Resize(input_size),\n","                    transforms.CenterCrop(input_size),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","                ]),\n","            }\n","            image_datasets = datasets.ImageFolder(base_dir, data_transforms['train'])\n","        # # Pretrainned\n","        # model_ft = model_ft.to(device)\n","        date_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n","        #aumentar numeros de splits depois\n","        kf = KFold(n_splits=10, shuffle=True, random_state=SEED)\n","        folds = kf.split(image_datasets)\n","        for fold, (train_idx, val_idx) in enumerate(folds):            \n","            model = basic_parameters.get('model_name')\n","            print(f'FOLD {fold}, Model: {model}, Augmentation: {type_aug}')\n","            train_dataset = torch.utils.data.Subset(image_datasets, train_idx)\n","            val_dataset = torch.utils.data.Subset(image_datasets, val_idx)\n","            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=basic_parameters.get('batch_size'), shuffle=True, num_workers=4)\n","            val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=basic_parameters.get('batch_size'), shuffle=True, num_workers=4)\n","            dataloaders_dict = {'train': train_loader, 'val': val_loader}\n","            # Reiniciar o modelo em cada fold\n","            #model_ft, input_size = initialize_model(basic_parameters.get('model_name'), basic_parameters.get('num_classes'))\n","            model_ft = model_ft.to(device)\n","            # Imprime o modelo\n","            # print(f'Model: {str(model_ft)}')\n","            # Otimizador\n","            optimizer = optim.SGD(model_ft.parameters(), lr=basic_parameters.get('lr'), momentum=basic_parameters.get('mm'))            \n","            model_ft = train_model(model_ft, dataloaders_dict, optimizer, basic_parameters, fold,date_now, device)\n","            model_ft.eval()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}
